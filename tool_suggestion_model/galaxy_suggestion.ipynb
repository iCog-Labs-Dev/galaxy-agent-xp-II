{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 1** - Importing Required modules to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model imported successfully\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import InputExample\n",
    "model = SentenceTransformer('intfloat/e5-base-v2')\n",
    "print(\"model imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 2** Loading The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Unzip collection\n",
      "Category: Collection Operations\n",
      "Help: Synopsis\n",
      "This tool takes a paired collection and \"unzips\" it into two simple dataset collections (lists of datasets).\n",
      "\n",
      "Description\n",
      "1. **Functionality**\n",
      "   - Given a paired collection of forward and re...\n",
      "--------------------------------------------------\n",
      "Name: Zip collections\n",
      "Category: Collection Operations\n",
      "Help: Synopsis\n",
      "This tool takes two collections and creates a paired collection from them.\n",
      "\n",
      "Description\n",
      "1. **Functionality**\n",
      "   - If you have one collection containing only forward reads and another containi...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Load the dataset\n",
    "with open(\"dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "for entry in data[:2]:  \n",
    "    print(f\"Name: {entry['name']}\")\n",
    "    print(f\"Category: {entry['category']}\")\n",
    "    print(f\"Help: {entry['help'][:200]}...\") \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 3** Extract The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 85\n"
     ]
    }
   ],
   "source": [
    "# Extract structured text data\n",
    "structured_data = [\n",
    "    {\"text\": f\"{entry['name']} - {entry['description']} - {entry['help']}\", \"category\": entry[\"category\"]}\n",
    "    for entry in data\n",
    "]\n",
    "\n",
    "# Creating training examples with category-based pairing\n",
    "train_examples = []\n",
    "num_entries = len(structured_data)\n",
    "print(f\"Number of entries: {num_entries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 4** Creating Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Training Pairs:\n",
      "['Unzip collection -  - Synopsis\\nThis tool takes a paired collection and \"unzips\" it into two simple dataset collections (lists of datasets).\\n\\nDescription\\n1. **Functionality**\\n   - Given a paired collection of forward and reverse reads, this tool separates them into two distinct collections.\\n   - The first output collection contains all forward reads, and the second output collection contains all reverse reads.\\n\\n2. **Use Case**\\n   - Useful for processing paired-end sequencing data.\\n   - Enables downstream analysis by handling forward and reverse reads separately.\\n\\nThis tool simplifies paired dataset management, allowing for more flexible analysis workflows in Galaxy.', 'Zip collections -  - Synopsis\\nThis tool takes two collections and creates a paired collection from them.\\n\\nDescription\\n1. **Functionality**\\n   - If you have one collection containing only forward reads and another containing only reverse reads, this tool will combine them into a paired collection.\\n   - The resulting collection maintains the pairing between corresponding forward and reverse reads.\\n\\n2. **Use Case**\\n   - Useful for handling paired-end sequencing data in workflows.\\n   - Ensures that forward and reverse reads are correctly associated for downstream analysis.\\n\\nThis tool simplifies dataset management by efficiently merging forward and reverse read collections into a structured paired collection.'] Label: 1.0\n",
      "['Unzip collection -  - Synopsis\\nThis tool takes a paired collection and \"unzips\" it into two simple dataset collections (lists of datasets).\\n\\nDescription\\n1. **Functionality**\\n   - Given a paired collection of forward and reverse reads, this tool separates them into two distinct collections.\\n   - The first output collection contains all forward reads, and the second output collection contains all reverse reads.\\n\\n2. **Use Case**\\n   - Useful for processing paired-end sequencing data.\\n   - Enables downstream analysis by handling forward and reverse reads separately.\\n\\nThis tool simplifies paired dataset management, allowing for more flexible analysis workflows in Galaxy.', 'Filter failed datasets -  - Synopsis\\nRemoves datasets in error (red) from a collection.\\n\\nDescription\\nThis tool takes a dataset collection and filters out (removes) datasets in the failed (red) state. This is useful for continuing a multi-sample analysis when one or more of the samples fails at some point.\\n\\nThis tool will create new history datasets from your collection but your quota usage will not increase.'] Label: 1.0\n",
      "['Unzip collection -  - Synopsis\\nThis tool takes a paired collection and \"unzips\" it into two simple dataset collections (lists of datasets).\\n\\nDescription\\n1. **Functionality**\\n   - Given a paired collection of forward and reverse reads, this tool separates them into two distinct collections.\\n   - The first output collection contains all forward reads, and the second output collection contains all reverse reads.\\n\\n2. **Use Case**\\n   - Useful for processing paired-end sequencing data.\\n   - Enables downstream analysis by handling forward and reverse reads separately.\\n\\nThis tool simplifies paired dataset management, allowing for more flexible analysis workflows in Galaxy.', 'Filter empty datasets -  - Synopsis\\nRemoves empty elements from a collection.\\n\\nDescription\\nThis tool takes a dataset collection and filters out (removes) empty datasets. This is useful for continuing a multi-sample analysis when downstream tools require datasets to have content.\\n\\nThis tool will create new history datasets from your collection but your quota usage will not increase.'] Label: 1.0\n",
      "['Unzip collection -  - Synopsis\\nThis tool takes a paired collection and \"unzips\" it into two simple dataset collections (lists of datasets).\\n\\nDescription\\n1. **Functionality**\\n   - Given a paired collection of forward and reverse reads, this tool separates them into two distinct collections.\\n   - The first output collection contains all forward reads, and the second output collection contains all reverse reads.\\n\\n2. **Use Case**\\n   - Useful for processing paired-end sequencing data.\\n   - Enables downstream analysis by handling forward and reverse reads separately.\\n\\nThis tool simplifies paired dataset management, allowing for more flexible analysis workflows in Galaxy.', 'Filter null elements -  - Synopsis\\nRemoves null elements from a collection.\\n\\nDescription\\nThis tool takes a dataset collection and filters out nulls. This is useful for removing elements that resulted from conditional execution of jobs.\\n\\nThis tool will create new history datasets from your collection but your quota usage will not increase.'] Label: 1.0\n",
      "['Unzip collection -  - Synopsis\\nThis tool takes a paired collection and \"unzips\" it into two simple dataset collections (lists of datasets).\\n\\nDescription\\n1. **Functionality**\\n   - Given a paired collection of forward and reverse reads, this tool separates them into two distinct collections.\\n   - The first output collection contains all forward reads, and the second output collection contains all reverse reads.\\n\\n2. **Use Case**\\n   - Useful for processing paired-end sequencing data.\\n   - Enables downstream analysis by handling forward and reverse reads separately.\\n\\nThis tool simplifies paired dataset management, allowing for more flexible analysis workflows in Galaxy.', 'Flatten collection -  - Synopsis\\nFlattens nested collection into a simple list.\\n\\nDescription\\nThis tool takes nested collections such as a list of lists or a list of dataset pairs and produces a flat list from the inputs. It effectively \"flattens\" the hierarchy. The collection identifiers are merged together (using \"_\" as default) to create new collection identifiers in the flattened result.'] Label: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create Positive Pairs (Same Category)\n",
    "for i in range(num_entries):\n",
    "    for j in range(i + 1, num_entries):\n",
    "        if structured_data[i][\"category\"] == structured_data[j][\"category\"]:\n",
    "            train_examples.append(InputExample(texts=[structured_data[i][\"text\"], structured_data[j][\"text\"]], label=1.0))\n",
    "\n",
    "# Create Negative Pairs (Different Categories)\n",
    "negative_pairs = []\n",
    "for i in range(num_entries):\n",
    "    for j in range(i + 1, num_entries):\n",
    "        if structured_data[i][\"category\"] != structured_data[j][\"category\"]:\n",
    "            negative_pairs.append((structured_data[i][\"text\"], structured_data[j][\"text\"]))\n",
    "\n",
    "# Sample Negative Pairs to balance dataset\n",
    "negative_pairs_sampled = random.sample(negative_pairs, len(train_examples))  # Match positive pair count\n",
    "\n",
    "for pair in negative_pairs_sampled:\n",
    "    train_examples.append(InputExample(texts=[pair[0], pair[1]], label=0.0))\n",
    "\n",
    "# Print sample pairs for verification\n",
    "print(\"Sample Training Pairs:\")\n",
    "for ex in train_examples[:5]:\n",
    "    print(ex.texts, \"Label:\", ex.label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 5** Define Data loader and Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, losses\n",
    "import datasets\n",
    "\n",
    "# Define a DataLoader\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=8)\n",
    "\n",
    "# Define the loss function for contrastive learning\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 6** Fine Tune SBERT Model With Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [188/188 02:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fine-tune the E5 model\n",
    "#model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=20, warmup_steps=100)\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100)\n",
    "# Save the fine-tuned model\n",
    "version = 3\n",
    "model.save(f\"fine_tuned_E5_for_galaxy_v{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02281008 -0.03698322 -0.0344712  ... -0.00136929  0.00334988\n",
      "   0.02803659]\n",
      " [ 0.01571156 -0.04223171 -0.0090887  ... -0.04540608 -0.00240785\n",
      "   0.01285199]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "fine_tuned_model = SentenceTransformer(f\"fine_tuned_E5_for_galaxy_v{version}\")\n",
    "sentences = [\"This tool helps in dataset filtering.\", \"Merging collections is useful.\"]\n",
    "embeddings = fine_tuned_model.encode(sentences)\n",
    "print(embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
